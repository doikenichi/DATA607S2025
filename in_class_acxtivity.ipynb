{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490ccc3b",
   "metadata": {},
   "source": [
    "# DATA 607 - Summer 2025\n",
    "\n",
    "## 2025.07.21\n",
    "\n",
    "### In-class activity - SMS spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9096214",
   "metadata": {},
   "source": [
    "#### The dataset\n",
    "\n",
    "In this activity, we'll try to flag spam SMS messages based on the text of the message.\n",
    "\n",
    "The dataset comes from the UCI Machine Learning Repository ([link](https://archive.ics.uci.edu/dataset/228/sms+spam+collection)).\n",
    "\n",
    "I preprocessed it a bit. Load it from `data/sms_spam.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652a59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                            message\n",
       "0    False  Go until jurong point, crazy.. Available only ...\n",
       "1    False                      Ok lar... Joking wif u oni...\n",
       "2     True  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    False  U dun say so early hor... U c already then say...\n",
       "4    False  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/sms_spam.csv\", dtype={\"is_spam\": bool})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7a988",
   "metadata": {},
   "source": [
    "The dataset is unbalanced, with spam messages making up the minority (positive) class.\n",
    "What proportion of messages in the dataset are spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b07f69",
   "metadata": {},
   "source": [
    "#### Manual feature extraction\n",
    "\n",
    "If you examine some of the messages in the dataset, you'll notice some patterns that you might exploit for classifying spam messages. \n",
    "\n",
    "Add the following features to the dataframe:\n",
    "\n",
    "- `length`, the length of a message, in characters,\n",
    "\n",
    "- `num_caps`, the number of capital letters in a message,\n",
    "\n",
    "- `proportion_caps` the proportion of capital letters in a message,\n",
    "\n",
    "- `num_digits`, the number of digits in a message,\n",
    "\n",
    "- `proportion_digits` the proportion of digits in a message,\n",
    "\n",
    "- binary features `contains_<char>` indicating whether each of the following characters occurs in a message:\n",
    "`@`, `#`, `$`, `*`, `/`, `:`, `-`, `+`, `Â£`, `(`, `)`, `[`, `]`, `;`, `<`, `>`, `?`\n",
    "\n",
    "Compute cross-validated accuracy, $F_1$, precision, and recall metrics for `LogisticRegression`, `SGDClassifier`, and `LinearSVC` models fit to the the data using these features that you extracted.\n",
    "If you do this using `cross_val_score`, you'll need to loop over the metrics yourself. If you use [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) instead (try it!) you can pass in a list of metrics.\n",
    "\n",
    "How do the models compare across the various metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11396541",
   "metadata": {},
   "source": [
    "#### Cross-validated metrics\n",
    "\n",
    "In applications like spam filtering, misclassifications may have asymmetric costs. The cost of missing an important message because it was classified as spam may be significantly higher than the cost of having to read and delete a spam message. For this reason, it's useful compute false positive and false negative rates (see below), rather than just the overall misclassification rate.\n",
    "\n",
    "These rates can be computed from the data in the [confusion matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).\n",
    "\n",
    "\n",
    "There is a also a nice utility `ConfusionMatrixDisplay` for displaying confusion matrices with row and column labels. Again, see [the docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay).\n",
    "\n",
    "Plot cross-validated confusion matrix displays for the various classifiers listed above. Which ones have the best false positive and false negative rates? Recall that a prediction is a\n",
    "\n",
    "- **true positive** if the true label is $1$ and the predicted label is $1$,\n",
    "- **false negative** if the true label is $1$ and the predicted label is $0$.\n",
    "- **false postive** if the true label is $0$ and the predicted label is $1$,\n",
    "- **true negative** if the true label is $0$ and the predicted label is $0$.\n",
    "\n",
    "Let $\\text{TP}$, $\\text{FN}$, $\\text{FP}$, and $\\text{TN}$ be the numbers of true positive, false negative, false positive, and false negative predictions, respectively.\n",
    "\n",
    "The **confusion matrix** of a binary classifier is the matrix\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\text{TN}&\\text{FP}\\\\\n",
    "\\text{FN}&\\text{TP}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "The confusion matrix can be computed using the compound metric [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), exported from the `sklearn.metrics` module. \n",
    "That module also exports a nice utility [`ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay) for displaying confusion matrices together with row and column labels. For more expository material on confusion matrices, see the [User Guide](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).\n",
    "\n",
    "\n",
    " The **true positive rate**, $\\text{TPR}$, of a predictor is defined by\n",
    "\n",
    "$$\n",
    "\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}.\n",
    "$$ \n",
    "\n",
    "Similarly, the **false negative rate**, $\\text{FNR}$, of a predictor is defined by\n",
    "$$\n",
    "\\text{FNR} = \\frac{\\text{FN}}{\\text{TP} + \\text{FN}}.\n",
    "$$\n",
    "\n",
    "Because the confusion matrix isn't a score, you can't simply pass is as the `scoring` argument of `cross_val_score` or `cross_validated` to get a cross-validated version. Instead, you need to generate *cross-validated predictions* using [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html), and then pass these to `confusion_matrix` together with the true labels.\n",
    "\n",
    "Compute and display confusion matrices for the classifier listed abouve. Use them to extract the true positive rate and false positive rate of each classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5cd43",
   "metadata": {},
   "source": [
    "#### Feature extraction with `CountVectorizer`\n",
    "\n",
    "Compute cross-validated accuracy, $F_1$, precision, and recall metrics for `LogisticRegression`, `SGDClassifier`, `LinearSVC`, and `MultinomialNB` models fit to the data, extracting features using `CountVectorizer`.\n",
    "How do the models compare across the various metrics?\n",
    "\n",
    "Can you improve performance by tuning parameters of the vectorizer or the classifier? Does swapping out `CountVectorizer` with `TfidfVectorizer` improve any metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be6020",
   "metadata": {},
   "source": [
    "#### Extensions\n",
    "\n",
    "At this point, I expect you to be out of time. If you're not...\n",
    "\n",
    "- Try using dense embeddings to extract features instead of `CountVectorizer`. Follow the approach I demonstrated in Lecture 5 with the GTE.\n",
    "\n",
    "- If you've seen ROC curves before (I haven't discussed them in class), use `roc_curve` to find a threshold probability for a logistic regression classifier ensuring a small false positive rate, say $0.02$. What is the corresponding true positive rate? How about accuracy, $F_1$, precision, and recall scores?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
